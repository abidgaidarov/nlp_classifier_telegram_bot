{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('aux/imdb.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df['sentiment'] = le.fit_transform(df['sentiment'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', \" \", text) \n",
    "    text = re.sub(r'#\\w+', ' ', text) \n",
    "    text = re.sub(r'\\d+', ' ', text) \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'<.*?>',' ', text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    One of the other reviewers has mentioned that ...\n",
       "1    A wonderful little production. <br /><br />The...\n",
       "2    I thought this was a wonderful way to spend ti...\n",
       "3    Basically there's a family where a little boy ...\n",
       "4    Petter Mattei's \"Love in the Time of Money\" is...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['review']\n",
    "text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production br br the filmin...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically theres a family where a little boy j...\n",
       "4        petter matteis love in the time of money is a ...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    im going to have to disagree with the previous...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treated = text.apply(clean)\n",
    "treated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_text = []\n",
    "for review in treated:\n",
    "    lemmatized_text.append(' '.join([wn_lemmatizer.lemmatize(word) for word in review.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_tokenizer = RegexpTokenizer('\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'hill',\n",
       " 'have',\n",
       " 'eye',\n",
       " 'ii',\n",
       " 'is',\n",
       " 'what',\n",
       " 'you',\n",
       " 'would',\n",
       " 'expect',\n",
       " 'it',\n",
       " 'to',\n",
       " 'be',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'more',\n",
       " 'of',\n",
       " 'course',\n",
       " 'it',\n",
       " 'not',\n",
       " 'going',\n",
       " 'to',\n",
       " 'be',\n",
       " 'an',\n",
       " 'oscar',\n",
       " 'nominated',\n",
       " 'film',\n",
       " 'it',\n",
       " 'just',\n",
       " 'pure',\n",
       " 'entertainment',\n",
       " 'which',\n",
       " 'you',\n",
       " 'can',\n",
       " 'just',\n",
       " 'lose',\n",
       " 'yourself',\n",
       " 'in',\n",
       " 'for',\n",
       " 'minutesbr',\n",
       " 'br',\n",
       " 'the',\n",
       " 'plot',\n",
       " 'is',\n",
       " 'basically',\n",
       " 'about',\n",
       " 'a',\n",
       " 'group',\n",
       " 'of',\n",
       " 'national',\n",
       " 'guard',\n",
       " 'trainee',\n",
       " 'who',\n",
       " 'find',\n",
       " 'themselves',\n",
       " 'battling',\n",
       " 'against',\n",
       " 'the',\n",
       " 'notorious',\n",
       " 'mutated',\n",
       " 'hillbilly',\n",
       " 'on',\n",
       " 'their',\n",
       " 'last',\n",
       " 'day',\n",
       " 'of',\n",
       " 'training',\n",
       " 'in',\n",
       " 'the',\n",
       " 'desert',\n",
       " 'it',\n",
       " 'just',\n",
       " 'them',\n",
       " 'fighting',\n",
       " 'back',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'film',\n",
       " 'which',\n",
       " 'includes',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'violence',\n",
       " 'which',\n",
       " 'is',\n",
       " 'basically',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'film',\n",
       " 'a',\n",
       " 'blood',\n",
       " 'and',\n",
       " 'gut',\n",
       " 'are',\n",
       " 'constantly',\n",
       " 'flying',\n",
       " 'around',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'thing',\n",
       " 'and',\n",
       " 'also',\n",
       " 'yet',\n",
       " 'another',\n",
       " 'graphic',\n",
       " 'rape',\n",
       " 'scene',\n",
       " 'which',\n",
       " 'is',\n",
       " 'pointlessly',\n",
       " 'thrown',\n",
       " 'in',\n",
       " 'to',\n",
       " 'shock',\n",
       " 'the',\n",
       " 'audiencebr',\n",
       " 'br',\n",
       " 'id',\n",
       " 'give',\n",
       " 'the',\n",
       " 'hill',\n",
       " 'have',\n",
       " 'eye',\n",
       " 'ii',\n",
       " 'out',\n",
       " 'of',\n",
       " 'for',\n",
       " 'pure',\n",
       " 'entertainment',\n",
       " 'and',\n",
       " 'that',\n",
       " 'only',\n",
       " 'although',\n",
       " 'even',\n",
       " 'then',\n",
       " 'i',\n",
       " 'found',\n",
       " 'myself',\n",
       " 'looking',\n",
       " 'at',\n",
       " 'my',\n",
       " 'watch',\n",
       " 'more',\n",
       " 'and',\n",
       " 'more',\n",
       " 'a',\n",
       " 'the',\n",
       " 'film',\n",
       " 'went',\n",
       " 'on',\n",
       " 'a',\n",
       " 'it',\n",
       " 'began',\n",
       " 'to',\n",
       " 'drag',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'it',\n",
       " 'continued',\n",
       " 'to',\n",
       " 'try',\n",
       " 'and',\n",
       " 'shock',\n",
       " 'the',\n",
       " 'audience',\n",
       " 'with',\n",
       " 'graphic',\n",
       " 'gore',\n",
       " 'and',\n",
       " 'the',\n",
       " 'occasional',\n",
       " 'jump',\n",
       " 'scene',\n",
       " 'just',\n",
       " 'to',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'the',\n",
       " 'audience',\n",
       " 'stay',\n",
       " 'awake',\n",
       " 'the',\n",
       " 'hill',\n",
       " 'have',\n",
       " 'eye',\n",
       " 'ii',\n",
       " 'is',\n",
       " 'just',\n",
       " 'decent',\n",
       " 'entertainment',\n",
       " 'something',\n",
       " 'to',\n",
       " 'pas',\n",
       " 'time',\n",
       " 'if',\n",
       " 'youre',\n",
       " 'bored',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'elsebr',\n",
       " 'br']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = reg_tokenizer.tokenize_sents(lemmatized_text)\n",
    "tokenized_text[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokenized_tweets = [] \n",
    "for i, element in enumerate(tokenized_text):\n",
    "    clean_tokenized_tweets.append(' '.join([word for word in element if word not in sw]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer ha mentioned watching oz episode ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wa wonderful way spend time hot summer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one reviewer ha mentioned watching oz episode ...          1\n",
       "1  wonderful little production br br filming tech...          1\n",
       "2  thought wa wonderful way spend time hot summer...          1\n",
       "3  basically family little boy jake think zombie ...          0\n",
       "4  petter matteis love time money visually stunni...          1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.concat([pd.Series(clean_tokenized_tweets, name='review'), \n",
    "                pd.Series(df['sentiment'], name='sentiment')], \n",
    "               axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(ngram_range=(1, 1))\n",
    "tfid = TfidfVectorizer(ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_representation = cvec.fit_transform(pd.Series(clean_tokenized_tweets))\n",
    "tfid_representation = tfid.fit_transform(pd.Series(clean_tokenized_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from sklearn.naive_bayes import GaussianNB\\nfrom catboost import CatBoostClassifier '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from sklearn.ensemble import RandomForestClassifier \"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\"\"\" from sklearn.naive_bayes import GaussianNB\n",
    "from catboost import CatBoostClassifier \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' gnb = GaussianNB()\\ncbc = CatBoostClassifier() '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" rfc = RandomForestClassifier() \"\"\"\n",
    "lrc = LogisticRegression(max_iter=1000)\n",
    "\"\"\" gnb = GaussianNB()\n",
    "cbc = CatBoostClassifier() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" X_train, X_test, y_train, y_test = train_test_split(cvec_representation, new_df['sentiment'], test_size=0.2, random_state=900) \""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" X_train, X_test, y_train, y_test = train_test_split(cvec_representation, new_df['sentiment'], test_size=0.2, random_state=900) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' rfc.fit(X_train, y_train)\\ncvec_rfc_pred = rfc.predict(X_test)\\ncvec_rfc_accuracy = accuracy_score(y_test, cvec_rfc_pred)\\ncvec_rfc_accuracy '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" rfc.fit(X_train, y_train)\n",
    "cvec_rfc_pred = rfc.predict(X_test)\n",
    "cvec_rfc_accuracy = accuracy_score(y_test, cvec_rfc_pred)\n",
    "cvec_rfc_accuracy \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' lrc.fit(X_train, y_train)\\ncvec_lrc_pred = lrc.predict(X_test)\\ncvec_lrc_accuracy = accuracy_score(y_test, cvec_lrc_pred)\\ncvec_lrc_accuracy '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" lrc.fit(X_train, y_train)\n",
    "cvec_lrc_pred = lrc.predict(X_test)\n",
    "cvec_lrc_accuracy = accuracy_score(y_test, cvec_lrc_pred)\n",
    "cvec_lrc_accuracy \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' cbc.fit(X_train, y_train)\\ncvec_cbc_pred = cbc.predict(X_test)\\ncvec_cbc_accuracy = accuracy_score(y_test, cvec_cbc_pred)\\ncvec_cbc_accuracy '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" cbc.fit(X_train, y_train)\n",
    "cvec_cbc_pred = cbc.predict(X_test)\n",
    "cvec_cbc_accuracy = accuracy_score(y_test, cvec_cbc_pred)\n",
    "cvec_cbc_accuracy \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' gnb.fit(X_train.toarray(), y_train)\\ncvec_gnb_pred = gnb.predict(X_test)\\ncvec_gnb_accuracy = accuracy_score(y_test, cvec_gnb_pred)\\ncvec_gnb_accuracy '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" gnb.fit(X_train.toarray(), y_train)\n",
    "cvec_gnb_pred = gnb.predict(X_test)\n",
    "cvec_gnb_accuracy = accuracy_score(y_test, cvec_gnb_pred)\n",
    "cvec_gnb_accuracy \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfid_representation, new_df['sentiment'], test_size=0.2, random_state=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' rfc.fit(X_train, y_train)\\ntfid_rfc_pred = rfc.predict(X_test)\\ntfid_rfc_accuracy = accuracy_score(y_test, tfid_rfc_pred)\\ntfid_rfc_accuracy '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" rfc.fit(X_train, y_train)\n",
    "tfid_rfc_pred = rfc.predict(X_test)\n",
    "tfid_rfc_accuracy = accuracy_score(y_test, tfid_rfc_pred)\n",
    "tfid_rfc_accuracy \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8951"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc = LogisticRegression(max_iter=1000)\n",
    "lrc.fit(X_train, y_train)\n",
    "tfid_lrc_pred = lrc.predict(X_test)\n",
    "tfid_lrc_accuracy = accuracy_score(y_test, tfid_lrc_pred)\n",
    "tfid_lrc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' cbc.fit(X_train, y_train)\\ntfid_cbc_pred = cbc.predict(X_test)\\ntfid_cbc_accuracy = accuracy_score(y_test, tfid_cbc_pred)\\ntfid_cbc_accuracy '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" cbc.fit(X_train, y_train)\n",
    "tfid_cbc_pred = cbc.predict(X_test)\n",
    "tfid_cbc_accuracy = accuracy_score(y_test, tfid_cbc_pred)\n",
    "tfid_cbc_accuracy \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' gnb.fit(X_train, y_train)\\ncvec_gnb_pred = gnb.predict(X_test)\\ncvec_gnb_accuracy = accuracy_score(y_test, cvec_gnb_pred)\\ncvec_gnb_accuracy '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" gnb.fit(X_train, y_train)\n",
    "cvec_gnb_pred = gnb.predict(X_test)\n",
    "cvec_gnb_accuracy = accuracy_score(y_test, cvec_gnb_pred)\n",
    "cvec_gnb_accuracy \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfid.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(tfid_representation, 'tfid_representation.pkl')\n",
    "dump(lrc, 'lrc.pkl')\n",
    "dump(tfid, 'tfid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_for_bot = tfid.fit(pd.Series(clean_tokenized_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfid_for_bot.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(tfid_for_bot, 'tfid_for_bot.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3662e90209839a50890fe6b4ba48058f4ed0e5c334ee0e06713f14ab271b8d0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
